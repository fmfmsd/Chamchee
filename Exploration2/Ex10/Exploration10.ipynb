{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 번역기를 만들어보자"
      ],
      "metadata": {
        "id": "ISXHWGF2eJ8X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "NOWZ8WjcWvGG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/exploration/Ex10/jpn.txt'\n",
        "lines = pd.read_csv(file_path, names=['eng', 'jpn', 'cc'], sep='\\t')\n",
        "print('전체 샘플의 수 : ', len(lines))\n",
        "lines.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "SgcE9Nv4Os5F",
        "outputId": "43504410-d08c-4d85-acc1-deff3881b155"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 수 :  93356\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     eng  \\\n",
              "51961                   He made a gesture of impatience.   \n",
              "44357                      Tom is studying music theory.   \n",
              "5210                                    He has two cats.   \n",
              "85381  Tell me why you were absent from school yester...   \n",
              "92634  If there's anything at all that you don't unde...   \n",
              "90252  Tom secretly read Mary's diary while she was t...   \n",
              "65796              Do your homework before you watch TV.   \n",
              "29243                          I saw him cross the road.   \n",
              "63941               I overslept so I was late to school.   \n",
              "69158             She lay on the bed with her eyes open.   \n",
              "\n",
              "                                        jpn  \\\n",
              "51961                 彼はもう我慢がならないという身振りをした。   \n",
              "44357                       トムは音楽理論を習っています。   \n",
              "5210                          彼は猫を二匹飼っています。   \n",
              "85381                     昨日学校を休んだ理由をいいなさい。   \n",
              "92634      何かわからないことがあったら、いつでも聞いてくれればいいからね。   \n",
              "90252  トムはメアリーがお風呂に入ってる隙に、彼女の日記をこっそり読んだんだよ。   \n",
              "65796                      テレビを見る前に宿題をしなさい。   \n",
              "29243                          彼が道路を渡るのを見た。   \n",
              "63941                       寝坊したから、学校に遅刻した。   \n",
              "69158                彼女は目を開けたままベッドに横になっていた。   \n",
              "\n",
              "                                                      cc  \n",
              "51961  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "44357  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
              "5210   CC-BY 2.0 (France) Attribution: tatoeba.org #7...  \n",
              "85381  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "92634  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "90252  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
              "65796  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
              "29243  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "63941  CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
              "69158  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a011a665-bfbc-4fb1-8955-a90013c51736\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>jpn</th>\n",
              "      <th>cc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51961</th>\n",
              "      <td>He made a gesture of impatience.</td>\n",
              "      <td>彼はもう我慢がならないという身振りをした。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44357</th>\n",
              "      <td>Tom is studying music theory.</td>\n",
              "      <td>トムは音楽理論を習っています。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5210</th>\n",
              "      <td>He has two cats.</td>\n",
              "      <td>彼は猫を二匹飼っています。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85381</th>\n",
              "      <td>Tell me why you were absent from school yester...</td>\n",
              "      <td>昨日学校を休んだ理由をいいなさい。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92634</th>\n",
              "      <td>If there's anything at all that you don't unde...</td>\n",
              "      <td>何かわからないことがあったら、いつでも聞いてくれればいいからね。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90252</th>\n",
              "      <td>Tom secretly read Mary's diary while she was t...</td>\n",
              "      <td>トムはメアリーがお風呂に入ってる隙に、彼女の日記をこっそり読んだんだよ。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65796</th>\n",
              "      <td>Do your homework before you watch TV.</td>\n",
              "      <td>テレビを見る前に宿題をしなさい。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29243</th>\n",
              "      <td>I saw him cross the road.</td>\n",
              "      <td>彼が道路を渡るのを見た。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63941</th>\n",
              "      <td>I overslept so I was late to school.</td>\n",
              "      <td>寝坊したから、学校に遅刻した。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69158</th>\n",
              "      <td>She lay on the bed with her eyes open.</td>\n",
              "      <td>彼女は目を開けたままベッドに横になっていた。</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a011a665-bfbc-4fb1-8955-a90013c51736')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a011a665-bfbc-4fb1-8955-a90013c51736 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a011a665-bfbc-4fb1-8955-a90013c51736');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = lines[['eng', 'jpn']][:3000] # 3000개 샘플 사용\n",
        "lines.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LN_YxNINaZFS",
        "outputId": "fa2fc84d-4984-4351-a551-0b63072f3244"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 eng       jpn\n",
              "2781  Don't give up.    降参するな。\n",
              "1064     I'm hungry.    腹減ったな。\n",
              "364        I'm busy.    忙しいです。\n",
              "2730  Can I hug you?  ぎゅーしていい？\n",
              "337        Hurry up.   さあ、急いで。"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-141f744d-2fc8-4487-ae57-167913d1a4d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>jpn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2781</th>\n",
              "      <td>Don't give up.</td>\n",
              "      <td>降参するな。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1064</th>\n",
              "      <td>I'm hungry.</td>\n",
              "      <td>腹減ったな。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>I'm busy.</td>\n",
              "      <td>忙しいです。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2730</th>\n",
              "      <td>Can I hug you?</td>\n",
              "      <td>ぎゅーしていい？</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>Hurry up.</td>\n",
              "      <td>さあ、急いで。</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-141f744d-2fc8-4487-ae57-167913d1a4d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-141f744d-2fc8-4487-ae57-167913d1a4d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-141f744d-2fc8-4487-ae57-167913d1a4d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 5개의 샘플이 출력 된 것을 확인 가능."
      ],
      "metadata": {
        "id": "nG4VFQAwvpJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 시작 토큰과 종료 토큰 추가\n",
        "sos_token = '\\t'\n",
        "eos_token = '\\n'\n",
        "\n",
        "lines.jpn = lines.jpn.apply(lambda x : '\\t ' + x + ' \\n')\n",
        "print(\"전체 샘플 수 : \", len(lines))\n",
        "lines.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "nX-02Cm-a9I7",
        "outputId": "a5bc7eab-5600-48ff-d36e-c85003b9181c"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 수 :  3000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                eng                  jpn\n",
              "2101  I lucked out.   \\t 私ね、運に恵まれてたわ。 \\n\n",
              "1553   I'm no fool.  \\t 僕は馬鹿なんかじゃないぞ。 \\n\n",
              "1004    I love her.   \\t 彼女のことが大好きです。 \\n\n",
              "1279    What is it?       \\t それは何ですか。 \\n\n",
              "1419   How are you?            \\t 元気？ \\n"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04d08c19-e669-44f1-a49b-5842293544a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>jpn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2101</th>\n",
              "      <td>I lucked out.</td>\n",
              "      <td>\\t 私ね、運に恵まれてたわ。 \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1553</th>\n",
              "      <td>I'm no fool.</td>\n",
              "      <td>\\t 僕は馬鹿なんかじゃないぞ。 \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>I love her.</td>\n",
              "      <td>\\t 彼女のことが大好きです。 \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1279</th>\n",
              "      <td>What is it?</td>\n",
              "      <td>\\t それは何ですか。 \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1419</th>\n",
              "      <td>How are you?</td>\n",
              "      <td>\\t 元気？ \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04d08c19-e669-44f1-a49b-5842293544a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04d08c19-e669-44f1-a49b-5842293544a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04d08c19-e669-44f1-a49b-5842293544a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenizer = Tokenizer(char_level = True) # \"문자\" 단위로 Tokenizer를 생성합니다.\n",
        "eng_tokenizer.fit_on_texts(lines.eng) # 50000개의 행을 가진 eng의 각 행에 토큰화를 수행\n",
        "input_text = eng_tokenizer.texts_to_sequences(lines.eng) # input단어를 숫자값 인덱스로 변환하여 저장 \n",
        "input_text[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAeZ3d00bTBc",
        "outputId": "79754101-19e9-4c1b-bf7c-5bfa4ad54e90"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[20, 4, 6], [20, 4, 6], [12, 3, 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jpn_tokenizer = Tokenizer(char_level = True) # 문자 단위로 Tokenizer 생성 (일본어)\n",
        "jpn_tokenizer.fit_on_texts(lines.jpn) # 3000개의 행을 가진 jpn의 각 행에 토큰화를 수행\n",
        "target_text = jpn_tokenizer.texts_to_sequences(lines.jpn) # 단어를 숫자값 인덱스로 변환하여 저장\n",
        "target_text[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIj9Nc_fbUGh",
        "outputId": "5f19ce2f-43a8-4bfa-b08d-9beb23a419c5"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 1, 50, 45, 4, 1, 3],\n",
              " [2, 1, 50, 34, 10, 26, 5, 4, 1, 3],\n",
              " [2, 1, 32, 28, 24, 39, 6, 4, 1, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "jpn_vocab_size = len(jpn_tokenizer.word_index) + 1\n",
        "print(\"영어 단어징의 크기 :\", eng_vocab_size)\n",
        "print(\"일본어어 단어장의 크기 :\", jpn_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4NBDW5dbd94",
        "outputId": "2e441381-a24c-4f80-aad9-1bc8b6c8dc23"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 단어징의 크기 : 46\n",
            "일본어어 단어장의 크기 : 873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_eng_seq_len = max([len(line) for line in input_text])\n",
        "max_jpn_seq_len = max([len(line) for line in target_text])\n",
        "\n",
        "print(\"영어 시퀀스의 최대 길이 : \", max_eng_seq_len)\n",
        "print(\"일본어 시퀀스의 최대 길이 : \", max_jpn_seq_len)"
      ],
      "metadata": {
        "id": "Q9ADo-KFZwMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "222b0f39-5142-4f12-847c-19bd089afd50"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 시퀀스의 최대 길이 :  14\n",
            "일본어 시퀀스의 최대 길이 :  30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"전체 샘플의 수 :\", len(lines))\n",
        "print(\"영어 단어장의 크기 :\", eng_vocab_size)\n",
        "print(\"일본어 단어장의 크기 :\", jpn_vocab_size)\n",
        "print(\"영어 시퀀스의 최대 길이 :\", max_eng_seq_len)\n",
        "print(\"일본어 시퀀스의 최대 길이 :\", max_jpn_seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXA9Sza_Z1HL",
        "outputId": "66d50fac-05ee-4a3e-cd6d-9b739892eee7"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 수 : 3000\n",
            "영어 단어장의 크기 : 46\n",
            "일본어 단어장의 크기 : 873\n",
            "영어 시퀀스의 최대 길이 : 14\n",
            "일본어 시퀀스의 최대 길이 : 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = input_text\n",
        "\n",
        "# 종료 토큰 제거\n",
        "decoder_input = [[char for char in line if char != jpn_tokenizer.word_index[eos_token]] for line in target_text]\n",
        "\n",
        "# 시작 토큰 제거\n",
        "decoder_target = [[char for char in line if char != jpn_tokenizer.word_index[sos_token]] for line in target_text]"
      ],
      "metadata": {
        "id": "5U-VOyr-fqhx"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder_input[:3])\n",
        "print(decoder_target[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlnjijOhfuw0",
        "outputId": "1bc790c7-c486-44c8-8acc-30509bb478f7"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 1, 50, 45, 4, 1], [2, 1, 50, 34, 10, 26, 5, 4, 1], [2, 1, 32, 28, 24, 39, 6, 4, 1]]\n",
            "[[1, 50, 45, 4, 1, 3], [1, 50, 34, 10, 26, 5, 4, 1, 3], [1, 32, 28, 24, 39, 6, 4, 1, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen = max_jpn_seq_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen = max_jpn_seq_len, padding='post') # 제로패딩\n",
        "\n",
        "print(\"영어 데이터의 크기(shape) :\", np.shape(encoder_input))\n",
        "print(\"일본어 입력 데이터의 크기(shape) :\", np.shape(decoder_input))\n",
        "print(\"일본어 출력 데이터의 크기(shape) :\", np.shape(decoder_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl2C0DAjfxhV",
        "outputId": "1febd461-cf6a-44f6-c71a-e685df937c61"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 데이터의 크기(shape) : (3000, 14)\n",
            "일본어 입력 데이터의 크기(shape) : (3000, 30)\n",
            "일본어 출력 데이터의 크기(shape) : (3000, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder_input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyLovlvdenXK",
        "outputId": "02665349-0715-4105-c079-691932e06a0f"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20  4  6  0  0  0  0  0  0  0  0  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)\n",
        "\n",
        "print(\"영어 데이터의 크기 (shape) :\", np.shape(encoder_input))\n",
        "print(\"일본어 입력데이터의 크기 (shape) :\", np.shape(decoder_input))\n",
        "print(\"일본어 출력데이터의 크기 (shape) :\", np.shape(decoder_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxWgkEuIbHHR",
        "outputId": "4f22f3e2-9e3d-46ed-8ad2-1dd756e7aff3"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 데이터의 크기 (shape) : (3000, 14, 46)\n",
            "일본어 입력데이터의 크기 (shape) : (3000, 30, 873)\n",
            "일본어 출력데이터의 크기 (shape) : (3000, 30, 873)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_val = 10 # 교차검증 횟수\n",
        "\n",
        "encoder_input_train = encoder_input[:-n_of_val] \n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]\n",
        "\n",
        "print(\"영어 학습 데이터의 크기 (shape) :\", np.shape(encoder_input))\n",
        "print(\"일본어 학습 입력데이터의 크기 (shape) :\", np.shape(decoder_input))\n",
        "print(\"일본어 학습 출력데이터의 크기 (shape) :\", np.shape(decoder_target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BScaTAybUB2",
        "outputId": "0e5545b0-25e6-4114-df23-a7090eed6c6b"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 학습 데이터의 크기 (shape) : (3000, 14, 46)\n",
            "일본어 학습 입력데이터의 크기 (shape) : (3000, 30, 873)\n",
            "일본어 학습 출력데이터의 크기 (shape) : (3000, 30, 873)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 훈련"
      ],
      "metadata": {
        "id": "IKZTw2ZAbnDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "03Z4fPwIbkRk"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 텐서 생성\n",
        "encoder_inputs = Input(shape=(None, eng_vocab_size))\n",
        "# hidden state가 256인 인코더의 LSTM 셸을 생성\n",
        "encoder_lstm = LSTM(units = 256, return_state = True)\n",
        "# 디코더로 전달할 hidden state, cell state를 리턴, encoder_outputs는 여기서는 불필요\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "# hidden state와 cell state를 다음 time step으로 전달하기 위해서 별도 저장\n",
        "encoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "wQU5eKX5bpW2"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 텐서 생성\n",
        "decoder_inputs = Input(shape=(None, jpn_vocab_size))\n",
        "# hidden size가 256인 인코더의 LSTM셸 생성\n",
        "decoder_lstm = LSTM(units = 256, return_sequences = True, return_state = True)\n",
        "# decoder_outputs는 모든 time step의 hidden state\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)"
      ],
      "metadata": {
        "id": "iszgOPq_buhp"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_softmax_layer = Dense(jpn_vocab_size, activation='softmax') # 최종 출력층 레이어\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs) "
      ],
      "metadata": {
        "id": "1p3qcQIZby68"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B83fzw1-b3Ds",
        "outputId": "a7c660ad-29a2-4363-94e3-2771f113306d"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_17 (InputLayer)          [(None, None, 46)]   0           []                               \n",
            "                                                                                                  \n",
            " input_18 (InputLayer)          [(None, None, 873)]  0           []                               \n",
            "                                                                                                  \n",
            " lstm_8 (LSTM)                  [(None, 256),        310272      ['input_17[0][0]']               \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_9 (LSTM)                  [(None, None, 256),  1157120     ['input_18[0][0]',               \n",
            "                                 (None, 256),                     'lstm_8[0][1]',                 \n",
            "                                 (None, 256)]                     'lstm_8[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, None, 873)    224361      ['lstm_9[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,691,753\n",
            "Trainable params: 1,691,753\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(\n",
        "    x=[encoder_input_train, decoder_input_train],\n",
        "    y = decoder_target_train,\n",
        "    validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "    batch_size = 128,\n",
        "    epochs = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5n05PDab5P7",
        "outputId": "a45bd7ba-f771-46b2-aa0d-348ee0d9f567"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 4s 53ms/step - loss: 2.4050 - val_loss: 1.3864\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.5198 - val_loss: 1.3298\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.4483 - val_loss: 1.2959\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.4171 - val_loss: 1.2790\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 1.3912 - val_loss: 1.2659\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.3417 - val_loss: 1.2226\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.2797 - val_loss: 1.2557\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.2091 - val_loss: 1.1251\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 1.1533 - val_loss: 1.0870\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.0942 - val_loss: 1.0630\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 1.0792 - val_loss: 1.0301\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.0279 - val_loss: 1.0448\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.0049 - val_loss: 1.0238\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.9791 - val_loss: 0.9993\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.9552 - val_loss: 0.9637\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.9572 - val_loss: 0.9682\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.9144 - val_loss: 0.9477\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.8916 - val_loss: 0.9419\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.8745 - val_loss: 0.9428\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.8567 - val_loss: 0.9290\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.8380 - val_loss: 0.8981\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.8165 - val_loss: 0.9301\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.7988 - val_loss: 0.8870\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.7813 - val_loss: 0.9273\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.7626 - val_loss: 0.8892\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.7457 - val_loss: 0.8835\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.7301 - val_loss: 0.8796\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.7139 - val_loss: 0.8983\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.6980 - val_loss: 0.8891\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.6829 - val_loss: 0.8898\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.6689 - val_loss: 0.8981\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.6543 - val_loss: 0.8834\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.6399 - val_loss: 0.9123\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.6278 - val_loss: 0.8674\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.6123 - val_loss: 0.9241\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.6013 - val_loss: 0.8777\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.5890 - val_loss: 0.9003\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.5765 - val_loss: 0.8877\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.5646 - val_loss: 0.8632\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.5517 - val_loss: 0.8900\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.5410 - val_loss: 0.8969\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.5318 - val_loss: 0.9217\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.5188 - val_loss: 0.8705\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.5080 - val_loss: 0.9028\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.4982 - val_loss: 0.8963\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.4859 - val_loss: 0.8708\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.4774 - val_loss: 0.8724\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.4667 - val_loss: 0.9212\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.4557 - val_loss: 0.9035\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.4440 - val_loss: 0.9084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "CNl15QbS2HC7",
        "outputId": "76fc1b98-d78f-41ee-fcd0-cdbf2a963919"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- train과 validation loss가 우하향 곡선을 가지긴한다.\n",
        "\n",
        "- val loss는 epoch 20회까지는 줄어들지만, 이후에는 변동이 사실상 없는 것 같다.(train 크기에 비해서 val의 크기가 커서 그런건지??)"
      ],
      "metadata": {
        "id": "YDafSYMQ2fBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
        "encoder_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVOEOGTqldIi",
        "outputId": "690b558c-a7b8-4ead-bead-cb348b6288fa"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, None, 46)]        0         \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               [(None, 256),             310272    \n",
            "                              (None, 256),                       \n",
            "                              (None, 256)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 310,272\n",
            "Trainable params: 310,272\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이전 time step의 hidden state를 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape = (256,))\n",
        "# 이전 time step의 cell state를 저장하는 텐서\n",
        "decoder_state_input_c = Input(shape = (256,))\n",
        "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# decoder_states_inputs를 현재 time_step의 초기 상태로 사용\n",
        "# 구체적인 동작 자체는 def decode_sequence()에 구현\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_states_inputs)\n",
        "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
        "decoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "BIsAClDYleuu"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs = [decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
        "decoder_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjrpDAIDlgFc",
        "outputId": "f4cd29bf-060c-4267-c7b2-67b32447c29a"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_18 (InputLayer)          [(None, None, 873)]  0           []                               \n",
            "                                                                                                  \n",
            " input_19 (InputLayer)          [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " input_20 (InputLayer)          [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " lstm_9 (LSTM)                  [(None, None, 256),  1157120     ['input_18[0][0]',               \n",
            "                                 (None, 256),                     'input_19[0][0]',               \n",
            "                                 (None, 256)]                     'input_20[0][0]']               \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, None, 873)    224361      ['lstm_9[1][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,381,481\n",
            "Trainable params: 1,381,481\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng2idx = eng_tokenizer.word_index\n",
        "jpn2idx = jpn_tokenizer.word_index\n",
        "idx2eng = eng_tokenizer.index_word\n",
        "idx2jpn = jpn_tokenizer.index_word"
      ],
      "metadata": {
        "id": "hlB7xYjGlhhr"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "    target_seq = np.zeros((1, 1, jpn_vocab_size))\n",
        "    target_seq[0, 0, jpn2idx['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    \n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    while not stop_condition:\n",
        "        # 이전 시점에서 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        \n",
        "        # 예측 결과를 문자로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = idx2jpn[sampled_token_index]\n",
        "        \n",
        "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "        decoded_sentence += sampled_char\n",
        "        \n",
        "        # <eos>에 도달하거나 최대 길이를 넘으면 중단\n",
        "        if (sampled_char == '\\n') or len(decoded_sentence) > max_jpn_seq_len:\n",
        "            stop_condition = True\n",
        "        \n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1, 1, jpn_vocab_size))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "        \n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value = [h, c]\n",
        "        \n",
        "    \n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "QLZ1BOTXlpDS"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "for seq_index in [0, 100, 20, 30, 500, 2100]:\n",
        "    input_seq = encoder_input[seq_index : seq_index+1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(35 * \"-\")\n",
        "    print(\"입력 문장 :\", lines.eng[seq_index])\n",
        "    print(\"정답 문장 :\", lines.jpn[seq_index][1:len(lines.jpn[seq_index]) -1])\n",
        "    print(\"번역기가 번약한 문장 :\", decoded_sentence[:len(decoded_sentence)-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el7R92rJlxcp",
        "outputId": "0ba3e990-5c8e-45e5-a054-fdfc0b91cc6e"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "-----------------------------------\n",
            "입력 문장 : Go.\n",
            "정답 문장 :  行け。 \n",
            "번역기가 번약한 문장 :  出て！ \n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "-----------------------------------\n",
            "입력 문장 : Listen.\n",
            "정답 문장 :  聞きなさい。 \n",
            "번역기가 번약한 문장 :  トムに聞いて。 \n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "-----------------------------------\n",
            "입력 문장 : Jump!\n",
            "정답 문장 :  跳べ！ \n",
            "번역기가 번약한 문장 :  飛び跳ねて！ \n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "-----------------------------------\n",
            "입력 문장 : Wait!\n",
            "정답 문장 :  待って！ \n",
            "번역기가 번약한 문장 :  待ってください。 \n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "-----------------------------------\n",
            "입력 문장 : Don't die.\n",
            "정답 문장 :  死なないで。 \n",
            "번역기가 번약한 문장 :  諦めなさい。 \n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "-----------------------------------\n",
            "입력 문장 : I lucked out.\n",
            "정답 문장 :  俺って、ツイてたよ。 \n",
            "번역기가 번약한 문장 :  私は運転します。 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 입력 문장 : Go. 정답 문장 :  行け。(가라.) 번역기가 번약한 문장 :  出て! (나가라!)\n",
        "2. 입력 문장 : Listen. (들어)\n",
        "정답 문장 :  聞きなさい。  (들으세요.)\n",
        "번역기가 번약한 문장 :  トムに聞いて。 (톰에게 **들었다.**)\n",
        "3. 입력 문장 : Jump! \n",
        "정답 문장 :  跳べ！ (뛰어!)\n",
        "번역기가 번약한 문장 :  飛び跳ねて！ (**뛰어 올라!**)\n",
        "\n",
        "4. 입력 문장 : Wait! \n",
        "정답 문장 :  待って！ (기다려!) \n",
        "번역기가 번약한 문장 :  待ってください。 (**기다려 주세요.**) \n",
        "5. 입력 문장 : Don't die.\n",
        "정답 문장 :  死なないで。 (죽지마.)\n",
        "번역기가 번약한 문장 :  諦めなさい。(포기해라)\n",
        "6. 입력 문장 : I lucked out. (나는 운이 좋다.)\n",
        "정답 문장 :  俺って、ツイてたよ。 (나에게 운이 들러붙었다.)\n",
        "번역기가 번약한 문장 :  私は運転します。 (나는 운전합니다/ 運転(*운*전) - 幸運(행*운*) '옮길 운'자를 사용 하긴했다. 아마도 ツイてたよ가 은어여서 제대로 구분을 못한 것 같다.)\n"
      ],
      "metadata": {
        "id": "n_8dAjg85czw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회고\n",
        "\n",
        "- seq2seq가 그림상으로는 간단하길래 금방 끝낼 거라 생각을 했는데, 지금까지 한 Exploration 중에서 가장 오래 잡고 있었던 것 같다.\n",
        "![gartner](https://github.com/fmfmsd/Chamchee/blob/main/Exploration2/Ex10/hype-cycle-for-artificial-intelligence-2022.png?raw=true)\n",
        "\n",
        "\n",
        "\n",
        "> 위 그래프를 보면 컴퓨터 비젼은 상용화에 가까워졌지만, NLP의 경우 상용화에 적어도 5~10년이 걸릴 것으로 예상이 된다고 한다.\n",
        "\n",
        "\n",
        "- 지금까지 NLP exploration은 기본중의 기본만 다루고 있는데도 불구하고, 내가 지금 정확히 어떻게 무엇을 하고 있는지 이해가 안되는 부분이 많다. 아이펠을 맨 처음에 시작할 때 난 꼭 CV를 해야지 라고 마음을 먹고 시작했지만, 오히려 시간이 지날수록 NLP쪽에 호기심이 생기고 있다."
      ],
      "metadata": {
        "id": "pj1oidA67mOI"
      }
    }
  ]
}